{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83b2be0c-70d6-4451-b999-a1c0b3542622",
   "metadata": {},
   "source": [
    "## First Steps\n",
    "\n",
    "Figure out Bayesian Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29f4a0f7-0ced-4c67-9cda-6d927980d915",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This lets me import the Python modules from the directory below this one\n",
    "import sys\n",
    "sys.path.insert(0, '../../reynard')\n",
    "from reynard_puzzle import Puzzle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4feca8b6-fcf4-4593-8e6c-1a1a1f08da32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pylab import *\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pyAgrum as gum\n",
    "import pyAgrum.lib.notebook as gnb\n",
    "from reynard_puzzle import Puzzle\n",
    "from reynard_agent import Agent\n",
    "from reynard_constants import letter_frequency, two_letter_word_frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2aeda2-9f64-4cb5-9b32-4212cfa010cf",
   "metadata": {},
   "source": [
    "## Baby Steps towards a BN\n",
    "\n",
    "How do I design it?  I need to experiment. My thoughts are that I can follow a pattern of looking for one letter words\n",
    "and then looking for two letter words and then three and so on.  The Network will get quite large.  Initially doing it by hand may lend itself to figuring out how to do it programatically.\n",
    "\n",
    "# OneLetterWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a560368a-3a28-49c2-b9c9-8834ef2ad96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Wrapper around the Bayesian Network\n",
    "bn=gum.BayesNet('cryptogram Solver')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "728559ce-eb60-4a29-8371-73c28e731e35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"182pt\" height=\"44pt\" viewBox=\"0.00 0.00 182.18 44.00\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 40)\">\n",
       "<title>G</title>\n",
       "<!-- OneLetterWords -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>OneLetterWords</title>\n",
       "<g id=\"a_node1\"><a xlink:title=\"(0) OneLetterWords\">\n",
       "<ellipse fill=\"#404040\" stroke=\"black\" cx=\"87.09\" cy=\"-18\" rx=\"87.18\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"87.09\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"white\">OneLetterWords</text>\n",
       "</a>\n",
       "</g>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "(pyAgrum.BayesNet<double>@0x5563dc134230) BN{nodes: 1, arcs: 0, domainSize: 2, dim: 2}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the startNode\n",
    "bn.add(gum.LabelizedVariable('OneLetterWords','Are there any one letter words?',['A','I']))\n",
    "# Assign Initial Probabilities\n",
    "bn.cpt('OneLetterWords').fillWith([0.5297,0.4703]);\n",
    "bn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b8d1b0-2fdd-472a-b0f7-aebc0f7326ca",
   "metadata": {},
   "source": [
    "## So Far\n",
    "\n",
    "At the moment we've created the start node.  Once the network is setup we can add follow on nodes.   So lets create a node for twoLetterWords and then connect the two\n",
    "\n",
    "# TwoLetterWords\n",
    "\n",
    "In working through the below cell I thought about using py_enchant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e89c27d-039a-49d4-b076-187bef044ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the startNode\n",
    "\n",
    "tlw = gum.LabelizedVariable('TwoLetterWords','Are there any two letter words?', two_letter_word_frequency)\n",
    "bn.add(tlw)\n",
    "# ['OF','TO','IN','IT','IS','BE','AS','AT','SO','WE','HE','BY','OR','ON','DO','IF','ME','MY', 'UP', 'AN','GO','NO','US', 'AM']\n",
    "# This is really dependent on knowing what character came in. We need to assign 0 probabilities to the ones that begin with a letter we don't know. \n",
    "temp_probsA = [0 for i in range(len(two_letter_word_frequency)) ]\n",
    "temp_probsI = [0 for i in range(len(two_letter_word_frequency))]\n",
    "for i in range(len(two_letter_word_frequency)):\n",
    "    if two_letter_word_frequency[i].startswith('A'):\n",
    "        temp_probsA[i] = letter_frequency[two_letter_word_frequency[i][1]]\n",
    "    elif two_letter_word_frequency[i].startswith('I'):\n",
    "        temp_probsI[i] = letter_frequency[two_letter_word_frequency[i][1]]\n",
    "# Now need to sum the arrays\n",
    "probsA = list(temp_probsA/sum(temp_probsA))\n",
    "probsI = list(temp_probsI/sum(temp_probsI))\n",
    "\n",
    "# Now we have the actual probabilities of the two letter words.  We can go one more once we know if A or I is picked but for initialization we'll just leave it like it is.\n",
    "bn.addArc('OneLetterWords','TwoLetterWords')\n",
    "bn.cpt('TwoLetterWords')[:]= [probsA,probsI]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30dbdc6c-71df-456a-a4e2-580f24fece7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.25656614459609994,\n",
       " 0.31095632412216545,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.29769206336424603,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.1347854679174887]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probsA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac993b57-f4d3-4cb6-9fdb-c352ebff3c46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border:1px solid black;\">\n",
       "<tr style='border:1px solid black;color:black;background-color:#808080'>\n",
       "      <th colspan='2'><center>OneLetterWords</center></th></tr>\n",
       "<tr><th style='border:1px solid black;border-bottom-style: double;color:black;background-color:#BBBBBB'>\n",
       "      <center>A</center></th><th style='border:1px solid black;border-bottom-style: double;color:black;background-color:#BBBBBB'>\n",
       "      <center>I</center></th></tr>\n",
       "<tr><td style='color:black;background-color:#bbc264;text-align:right;'>0.5297</td><td style='color:black;background-color:#c2bb64;text-align:right;'>0.4703</td></tr>\n",
       "</table>"
      ],
      "text/plain": [
       "(pyAgrum.Potential<double>@0x5563dbfa2690) \n",
       "  OneLetterWords   |\n",
       "A        |I        |\n",
       "---------|---------|\n",
       " 0.5297  | 0.4703  |"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn.cpt(\"OneLetterWords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373a69ca-820d-4f3e-bc15-106ba3bf2ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "bn.cpt(\"TwoLetterWords\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc85e79-0a7c-481f-8807-e49080215a4f",
   "metadata": {},
   "source": [
    "# Now Do Inference\n",
    "\n",
    "This uses the LazyPropogation *\"an exact inference method that transforms the Bayesian network into a hypergraph called a join tree or a junction tree. This tree is constructed in order to optimize inference computations.\"*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3f411d-4ec7-4e62-b3b9-a858e79d3539",
   "metadata": {},
   "outputs": [],
   "source": [
    "ie=gum.LazyPropagation(bn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9dc5bd3-0204-46f5-bad9-28463c6459b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ie.makeInference()\n",
    "gnb.showProba(ie.posterior(\"TwoLetterWords\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d50a18-910f-41fb-9e89-4d0581de89ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb.showInference(bn,evs={})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b830c4-4dad-43dd-8016-cdfb7ee94e7c",
   "metadata": {},
   "source": [
    "## Now lets set the OneLetterWord to A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e979d0-89c7-4afa-b15b-5ac71b8d3940",
   "metadata": {},
   "outputs": [],
   "source": [
    "ie.setEvidence({\"OneLetterWords\":[1.0,0.0]})\n",
    "ie.makeInference()\n",
    "ie.posterior(\"TwoLetterWords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6870e58e-8a4e-4734-a195-f31059fc6552",
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb.showProba(ie.posterior(\"TwoLetterWords\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc65affb-72bc-4bc0-9369-040f743bb436",
   "metadata": {},
   "outputs": [],
   "source": [
    "print()\n",
    "print(\"Word Suggestion is {} with probability of {}.\".format(two_letter_word_frequency[ie.posterior(\"TwoLetterWords\")[:].argmax()],ie.posterior(\"TwoLetterWords\")[:][ie.posterior(\"TwoLetterWords\")[:].argmax()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c134d3-6629-49e3-b89f-fce5c1ad3fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704c37a4-c68e-4e35-a9d5-6f6408abef02",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
